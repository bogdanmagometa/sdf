{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./nglod/sdf-net')\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/titan/bohdan/miniconda3/envs/nglod/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from lib.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_parser():\n",
    "        # New CLI parser\n",
    "    parser = argparse.ArgumentParser(description='Train deep implicit 3D geometry representations.')\n",
    "    \n",
    "    # Global arguments\n",
    "    global_group = parser.add_argument_group('global')\n",
    "    global_group.add_argument('--exp-name', type=str,\n",
    "                              help='Experiment name.')\n",
    "    global_group.add_argument('--perf', action='store_true',\n",
    "                              help='Use profiling.')\n",
    "    global_group.add_argument('--validator', type=str, default=None,\n",
    "                              help='Run validation.')\n",
    "    global_group.add_argument('--valid-only', action='store_true',\n",
    "                              help='Run validation (and do not run training).')\n",
    "    global_group.add_argument('--valid-every', type=int, default=1,\n",
    "                             help='Frequency of running validation.')\n",
    "    global_group.add_argument('--debug', action='store_true',\n",
    "                              help='Utility argument for debug output and viz.')\n",
    "    global_group.add_argument('--seed', type=int,\n",
    "                              help='NumPy random seed.')\n",
    "    global_group.add_argument('--ngc', action='store_true',\n",
    "                              help='Use NGC arguments.')\n",
    "\n",
    "    # Architecture for network\n",
    "    net_group = parser.add_argument_group('net')\n",
    "    net_group.add_argument('--net', type=str, default='OverfitSDF', \n",
    "                          help='The network architecture to be used.')\n",
    "    net_group.add_argument('--jit', action='store_true',\n",
    "                          help='Use JIT.')\n",
    "    net_group.add_argument('--pos-enc', action='store_true', \n",
    "                          help='Use positional encoding.')\n",
    "    net_group.add_argument('--feature-dim', type=int, default=32,\n",
    "                          help='Feature map dimension')\n",
    "    net_group.add_argument('--feature-size', type=int, default=4,\n",
    "                          help='Feature map size (w/h)')\n",
    "    net_group.add_argument('--joint-feature', action='store_true',\n",
    "                          help='Use joint features')\n",
    "    net_group.add_argument('--num-layers', type=int, default=1,\n",
    "                          help='Number of layers for the decoder')\n",
    "    net_group.add_argument('--num-lods', type=int, default=1,\n",
    "                          help='Number of LODs')\n",
    "    net_group.add_argument('--base-lod', type=int, default=2,\n",
    "                          help='Base level LOD')\n",
    "    net_group.add_argument('--ff-dim', type=int, default=-1,\n",
    "                          help='Fourier feature dimension.')\n",
    "    net_group.add_argument('--ff-width', type=float, default='16.0',\n",
    "                          help='Fourier feature width.')\n",
    "    net_group.add_argument('--hidden-dim', type=int, default=128,\n",
    "                          help='Network width')\n",
    "    net_group.add_argument('--pretrained', type=str,\n",
    "                          help='Path to pretrained model weights.')\n",
    "    net_group.add_argument('--periodic', action='store_true',\n",
    "                          help='Use periodic activations.')\n",
    "    net_group.add_argument('--skip', type=int, default=None,\n",
    "                          help='Layer to have skip connection.')\n",
    "    net_group.add_argument('--freeze', type=int, default=-1,\n",
    "                          help='Freeze the network at the specified epoch.')\n",
    "    net_group.add_argument('--pos-invariant', action='store_true',\n",
    "                          help='Use a position invariant network.')\n",
    "    net_group.add_argument('--joint-decoder', action='store_true',\n",
    "                          help='Use a single joint decoder.')\n",
    "    net_group.add_argument('--feat-sum', action='store_true',\n",
    "                          help='Sum the features.')\n",
    "\n",
    "    # Arguments for dataset\n",
    "    data_group = parser.add_argument_group('dataset')\n",
    "\n",
    "    # Mesh Dataset\n",
    "    data_group.add_argument('--dataset-path', type=str,\n",
    "                            help='Path of dataset')\n",
    "    data_group.add_argument('--analytic', action='store_true',\n",
    "                            help='Use analytic dataset')\n",
    "    data_group.add_argument('--mesh-dataset', type=str, default='MeshDataset',\n",
    "                            help='Mesh dataset class')\n",
    "    data_group.add_argument('--raw-obj-path', type=str, default=None,\n",
    "                            help='Raw mesh root directory to be preprocessed')\n",
    "    data_group.add_argument('--mesh-batch', action='store_true',\n",
    "                            help='Batch meshes together')\n",
    "    data_group.add_argument('--mesh-subset-size', type=int, default=-1,\n",
    "                            help='Mesh dataset subset (e.g. for ShapeNet, per category); default uses all')\n",
    "    data_group.add_argument('--train-valid-split', type=str, default=None,\n",
    "                            help='Path to train/valid dataset split dictionary (JSON)')\n",
    "    data_group.add_argument('--num-samples', type=int, default=100000,\n",
    "                            help='Number of samples per mode (or per epoch for SPC)')\n",
    "    data_group.add_argument('--samples-per-voxel', type=int, default=256,\n",
    "                            help='Number of samples per voxel (for SPC)')\n",
    "    data_group.add_argument('--sample-mode', type=str, nargs='*', \n",
    "                            default=['rand', 'near', 'near', 'trace', 'trace'],\n",
    "                            help='The sampling scheme to be used.')\n",
    "    data_group.add_argument('--trim', action='store_true',\n",
    "                            help='Trim inner triangles (will destroy UVs!).')\n",
    "    data_group.add_argument('--sample-tex', action='store_true',\n",
    "                            help='Sample textures')\n",
    "    data_group.add_argument('--block-res', type=int, default=7,\n",
    "                            help='Resolution of blocks')\n",
    "\n",
    "    # Analytic Dataset\n",
    "    data_group.add_argument('--include', nargs='*', \n",
    "                            help='Shapes to include (all shapes are included by default).')\n",
    "    data_group.add_argument('--exclude', nargs='*', \n",
    "                            help='Shapes to exclude.')\n",
    "    data_group.add_argument('--glsl-path', type=str, default='../sdf-viewer/data-files/sdf', \n",
    "                            help='Path to the GLSL shaders to sample.')\n",
    "    data_group.add_argument('--viewer-path', type=str, default='../sdf-viewer', \n",
    "                            help='Path to the viewer.')\n",
    "    data_group.add_argument('--get-normals', action='store_true',\n",
    "                            help='Sample the normals.')\n",
    "    data_group.add_argument('--build-dataset', action='store_true',\n",
    "                            help='Builds the dataset.')\n",
    "\n",
    "    # Arguments for optimizer\n",
    "    optim_group = parser.add_argument_group('optimizer')\n",
    "    optim_group.add_argument('--optimizer', type=str, default='adam', choices=['adam', 'sgd'], \n",
    "                             help='Optimizer to be used.')\n",
    "    optim_group.add_argument('--lr', type=float, default=0.001, \n",
    "                             help='Learning rate.')\n",
    "    optim_group.add_argument('--loss', nargs='+', type=str, \n",
    "                             default=['l2_loss'], help='Objective function/loss.')\n",
    "    optim_group.add_argument('--grad-method', type=str, choices=['autodiff', 'finitediff'], \n",
    "                             default='finitediff', help='Mode of gradient computations.')\n",
    " \n",
    "    # Arguments for training\n",
    "    train_group = parser.add_argument_group('trainer')\n",
    "    train_group.add_argument('--epochs', type=int, default=250, \n",
    "                             help='Number of epochs to run the training.')\n",
    "    train_group.add_argument('--batch-size', type=int, default=512, \n",
    "                             help='Batch size for the training.')\n",
    "    train_group.add_argument('--only-last', action='store_true', \n",
    "                             help='Train only last LOD.')\n",
    "    train_group.add_argument('--resample-every', type=int, default=10,\n",
    "                             help='Resample every N epochs')\n",
    "    train_group.add_argument('--model-path', type=str, default='_results/models', \n",
    "                             help='Path to save the trained models.')\n",
    "    train_group.add_argument('--save-as-new', action='store_true', \n",
    "                             help='Save the model at every epoch (no overwrite).')\n",
    "    train_group.add_argument('--save-every', type=int, default=1, \n",
    "                             help='Save the model at every N epoch.')\n",
    "    train_group.add_argument('--save-all', action='store_true', \n",
    "                             help='Save the entire model')\n",
    "    train_group.add_argument('--latent', action='store_true', \n",
    "                             help='Train latent space.')\n",
    "    train_group.add_argument('--return-lst', action='store_true', \n",
    "                             help='Returns a list of predictions (optimization).')\n",
    "    train_group.add_argument('--latent-dim', type=int, default=128, \n",
    "                             help='Latent vector dimension.')\n",
    "    train_group.add_argument('--logs', type=str, default='_results/logs/runs/',\n",
    "                             help='Log file directory for checkpoints.')\n",
    "    train_group.add_argument('--grow-every', type=int, default=-1,\n",
    "                             help='Grow network every X epochs')\n",
    "    train_group.add_argument('--loss-sample', type=int, default=-1,\n",
    "                             help='Sample Nx points for loss importance sampling')\n",
    "    # One by one trains one level at a time. \n",
    "    # Increase starts from [0] and ends up at [0,...,N]\n",
    "    # Shrink strats from [0,...,N] and ends up at [N]\n",
    "    # Fine to coarse starts from [N] and ends up at [0,...,N]\n",
    "    # Only last starts and ends at [N]\n",
    "    train_group.add_argument('--growth-strategy', type=str, default='increase',\n",
    "                             choices=['onebyone','increase','shrink', 'finetocoarse', 'onlylast'],\n",
    "                             help='Strategy for coarse-to-fine training')\n",
    "            \n",
    "    # Arguments for renderer\n",
    "    renderer_group = parser.add_argument_group('renderer')\n",
    "    renderer_group.add_argument('--sol', action='store_true',\n",
    "                                help='Use the SOL mode renderer.')\n",
    "    renderer_group.add_argument('--render-res', type=int, nargs=2, default=[512, 512], \n",
    "                                help='Width/height to render at.')\n",
    "    renderer_group.add_argument('--render-batch', type=int, default=0, \n",
    "                                help='Batch size for batched rendering.')\n",
    "    renderer_group.add_argument('--matcap-path', type=str, \n",
    "                                default='data/matcap/green.png', \n",
    "                                help='Path to the matcap texture to render with.')\n",
    "    renderer_group.add_argument('--camera-origin', type=float, nargs=3, default=[-2.8, 2.8, -2.8], \n",
    "                                help='Camera origin.')\n",
    "    renderer_group.add_argument('--camera-lookat', type=float, nargs=3, default=[0, 0, 0], \n",
    "                                help='Camera look-at/target point.')\n",
    "    renderer_group.add_argument('--camera-fov', type=float, default=30, \n",
    "                                help='Camera field of view (FOV).')\n",
    "    renderer_group.add_argument('--camera-proj', type=str, choices=['ortho', 'persp'], default='persp', \n",
    "                                help='Camera projection.')\n",
    "    renderer_group.add_argument('--camera-clamp', nargs=2, type=float, default=[-5, 10], \n",
    "                                help='Camera clipping bounds.')\n",
    "    renderer_group.add_argument('--lod', type=int, default=None, \n",
    "                                help='LOD level to use.')\n",
    "    renderer_group.add_argument('--interpolate', type=float, default=None,\n",
    "                                help='LOD interpolation value')\n",
    "    renderer_group.add_argument('--render-every', type=int, default=1,\n",
    "                                help='Render every N epochs')\n",
    "    renderer_group.add_argument('--num-steps', type=int, default=256,\n",
    "                                help='Number of steps')\n",
    "    renderer_group.add_argument('--step-size', type=float, default=1.0,\n",
    "                                help='Scale of step size')\n",
    "    renderer_group.add_argument('--min-dis', type=float, default=0.0003,\n",
    "                                help='Minimum distance away from surface')\n",
    "    renderer_group.add_argument('--ground-height', type=float,\n",
    "                                help='Ground plane y coords')\n",
    "    renderer_group.add_argument('--tracer', type=str, default='SphereTracer', \n",
    "                                help='The tracer to be used.')\n",
    "    renderer_group.add_argument('--ao', action='store_true',\n",
    "                                help='Use ambient occlusion.')\n",
    "    renderer_group.add_argument('--shadow', action='store_true',\n",
    "                                help='Use shadowing.')\n",
    "    renderer_group.add_argument('--shading-mode', type=str, default='matcap',\n",
    "                                help='Shading mode.')\n",
    "    return parser\n",
    "\n",
    "import pprint\n",
    "def args_to_str(args, parser):\n",
    "    \"\"\"Convert args to string representation for Tensorboard logging.\n",
    "\n",
    "    Args:\n",
    "        parser (argparse.parser): CLI parser\n",
    "    \"\"\"\n",
    "\n",
    "    args_dict = {}\n",
    "    for group in parser._action_groups:\n",
    "        group_dict = {a.dest:getattr(args, a.dest, None) for a in group._group_actions}\n",
    "        args_dict[group.title] = vars(argparse.Namespace(**group_dict))\n",
    "\n",
    "    pp = pprint.PrettyPrinter(indent=2)\n",
    "    args_str = pp.pformat(args_dict)\n",
    "    args_str = f'```{args_str}```'\n",
    "\n",
    "    return args_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = build_parser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = parser.parse_args([\n",
    "    '--net', 'OctreeSDF', \n",
    "    '--num-lods', '5', \n",
    "    '--dataset-path', '../../test_task_meshes/0.obj', \n",
    "    '--epoch', '250',\n",
    "    '--exp-name', '0'\n",
    "    ])\n",
    "args_str = args_to_str(args, parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomizedTrainer(Trainer):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=47 error=100 : no CUDA-capable device is detected\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (100) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:47",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mCustomizedTrainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model.train()\u001b[39;00m\n",
      "File \u001b[0;32m/titan/bohdan/sdf/./nglod/sdf-net/lib/trainer.py:105\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, args, args_str)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs_str \u001b[38;5;241m=\u001b[39m args_str\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mepochs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimer \u001b[38;5;241m=\u001b[39m \u001b[43mPerfTimer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactivate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mperf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimer\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# Set device to use\u001b[39;00m\n",
      "File \u001b[0;32m/titan/bohdan/sdf/./nglod/sdf-net/lib/utils.py:100\u001b[0m, in \u001b[0;36mPerfTimer.__init__\u001b[0;34m(self, activate)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mEvent(enable_timing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mend \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mEvent(enable_timing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev_time_gpu \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecord\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcounter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivate \u001b[38;5;241m=\u001b[39m activate\n",
      "File \u001b[0;32m/titan/bohdan/miniconda3/envs/nglod/lib/python3.8/site-packages/torch/cuda/streams.py:148\u001b[0m, in \u001b[0;36mEvent.record\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Records the event in a given stream.\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \n\u001b[1;32m    145\u001b[0m \u001b[38;5;124;03mUses ``torch.cuda.current_stream()`` if no stream is specified. The\u001b[39;00m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;124;03mstream's device must match the event's device.\"\"\"\u001b[39;00m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 148\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28msuper\u001b[39m(Event, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mrecord(stream)\n",
      "File \u001b[0;32m/titan/bohdan/miniconda3/envs/nglod/lib/python3.8/site-packages/torch/cuda/__init__.py:423\u001b[0m, in \u001b[0;36mcurrent_stream\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_stream\u001b[39m(device: Optional[_device_t] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Stream:\n\u001b[1;32m    415\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the currently selected :class:`Stream` for a given device.\u001b[39;00m\n\u001b[1;32m    416\u001b[0m \n\u001b[1;32m    417\u001b[0m \u001b[38;5;124;03m    Arguments:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[38;5;124;03m            (default).\u001b[39;00m\n\u001b[1;32m    422\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 423\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Stream(_cdata\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getCurrentStream(\n\u001b[1;32m    425\u001b[0m         _get_device_index(device, optional\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)))\n",
      "File \u001b[0;32m/titan/bohdan/miniconda3/envs/nglod/lib/python3.8/site-packages/torch/cuda/__init__.py:190\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 190\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    194\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (100) : no CUDA-capable device is detected at /pytorch/aten/src/THC/THCGeneral.cpp:47"
     ]
    }
   ],
   "source": [
    "model = CustomizedTrainer(args, args_str)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nglod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
